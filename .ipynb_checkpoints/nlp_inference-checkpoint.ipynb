{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import jieba\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from jaccard_index.jaccard import jaccard_index\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from scipy import spatial\n",
    "from scipy.spatial import distance\n",
    "import pickle\n",
    "import nltk\n",
    "import lightgbm as lgb\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model\n",
      "Finish loading model\n"
     ]
    }
   ],
   "source": [
    "from jslearn import nlp\n",
    "embedding = nlp.TencentWordEmbedding()\n",
    "embedding.load_pretrained('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading x and y removed from training\n",
    "x_r = open('./x_removed_final.plk','rb')\n",
    "x_removed_final = pickle.load(open('./x_removed_final.plk','rb'))\n",
    "x_r.close()\n",
    "y_r = open('./y_removed_final.plk','rb')\n",
    "y_removed_final = pickle.load(open('./y_removed_final.plk','rb'))\n",
    "y_r.close()\n",
    "unique_name_r = open('./unique_name.plk','rb')\n",
    "unique_name = pickle.load(open('./unique_name.plk','rb'))\n",
    "unique_name_r.close()\n",
    "data_unique_item_r = open('./data_unique_item.plk','rb')\n",
    "data_unique_item = pickle.load(open('./data_unique_item.plk','rb'))\n",
    "data_unique_item_r.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst = joblib.load('model.pkl') # load model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vec(x):\n",
    "    '''get the vector from name, if name not found in tencent trained,\n",
    "    split words and try to get vector from each splitted then avereage,\n",
    "    if it does not exist, return null'''\n",
    "    try:\n",
    "        vector = embedding.tc_wv.get_vector(x)\n",
    "#         print(x + 'full line processed')\n",
    "    except:\n",
    "        lst = list(jieba.cut(x))\n",
    "        to_avg = []\n",
    "        to_div = 0\n",
    "        for x in lst:\n",
    "            try:\n",
    "                to_avg += [embedding.tc_wv.get_vector(x)]\n",
    "                to_div += 1\n",
    "            except:\n",
    "                pass\n",
    "        if to_div != 0:\n",
    "            vector = sum(to_avg)/to_div\n",
    "#             print(x + 'trimmed processed')\n",
    "        else:\n",
    "            vector = None\n",
    "#             print('word does not match')\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_item_df(prod_name,x_removed_final,y_removed_final):\n",
    "    '''\n",
    "    取得一个产品每一个可能的组合的类别,并得出语义cosine similarity,编辑距离, 跟利维坦距离\n",
    "    extract the product_name and all its possible combination with y(all the unique categories name)'s cos sim, jac_score, and lev_distance.\n",
    "    \n",
    "    Parameters:\n",
    "    prod_name (str): any product name\n",
    "    x_removed_final (list): a list of x to remove (derived from train_n_filter)\n",
    "    y_removed_final (list): a list of y to remove (derived from train_n_filter)\n",
    "    \n",
    "    Returns:\n",
    "    dataframe of every possible categorical combination and its fellow scores, or None if the prod_name cannot be detected'''\n",
    "    inference_df = pd.DataFrame()\n",
    "    def jac_calc(y):\n",
    "        try:\n",
    "            return jaccard_index(prod_name,y['name'])\n",
    "        except:\n",
    "            return 0\n",
    "    unique_name_c  = unique_name.copy()\n",
    "    \n",
    "    #remove x and y that were not trained\n",
    "    if prod_name in x_removed_final:\n",
    "        return \n",
    "    unique_name_c = unique_name_c[unique_name_c['name'].apply(lambda x: True if x not in y_removed_final else False)]\n",
    "    \n",
    "    cos_score = unique_name_c.apply(lambda y: 1 - spatial.distance.cosine(get_vec(prod_name),y['y_vec']), axis = 1)# get cosine similarity score for semantic\n",
    "    jac_score = unique_name_c.apply(lambda y: jac_calc(y),axis =1) # get jaccard similarity score for vocab distance\n",
    "    lev_distance = unique_name_c.apply(lambda y: nltk.edit_distance(prod_name,y['name']), axis = 1)\n",
    "\n",
    "    xy_df = pd.DataFrame()\n",
    "    xy_df['y_name'] = unique_name_c['name']\n",
    "    xy_df['x_name'] = prod_name\n",
    "    xy_df['cos'] = cos_score\n",
    "    xy_df['jac'] = jac_score\n",
    "    xy_df['lev'] = lev_distance\n",
    "    xy_df['len(x)'] = len(prod_name)\n",
    "    xy_df['len(y)'] = unique_name_c['name'].apply(lambda y: len(y))\n",
    "    inference_df = inference_df.append(xy_df)\n",
    "    inference_df = inference_df.reset_index(drop = True)\n",
    "    return inference_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inference_data(data_unique_item,x_removed_final,y_removed_final):\n",
    "    '''\n",
    "    取得所有产品每一个可能的组合的类别,并得出语义cosine similarity,编辑距离, 跟利维坦距离\n",
    "    extract the product_name and all its possible combination with y(all the unique categories name)'s cos sim, jac_score, and lev_distance\n",
    "    \n",
    "    Parameters:\n",
    "    prod_name (str): any product name\n",
    "    x_removed_final (list): a list of x to remove (derived from train_n_filter)\n",
    "    y_removed_final (list): a list of y to remove (derived from train_n_filter)\n",
    "    \n",
    "    Returns:\n",
    "    dataframe of every possible categorical combination and its fellow scores'''\n",
    "    ml_ready_df = pd.DataFrame()\n",
    "    for row_tuple in data_unique_item.iterrows():\n",
    "        row = row_tuple[1]\n",
    "        def jac_calc(y):\n",
    "            try:\n",
    "                return jaccard_index(row['S_SEGMENT_ITEM'],y['name'])\n",
    "            except:\n",
    "                return 0\n",
    "        #remove x and y that were not trained\n",
    "        if ((row['S_SEGMENT_ITEM'] in x_removed_final) | (row['name'] in y_removed_final)):\n",
    "#             print(row['S_SEGMENT_ITEM'])\n",
    "#             print(row['name'])\n",
    "#             print('pass')\n",
    "            continue\n",
    "        unique_name_c  = unique_name.copy()\n",
    "\n",
    "        cos_score = unique_name_c.apply(lambda y: 1 - spatial.distance.cosine(get_vec(row['S_SEGMENT_ITEM']),y['y_vec']), axis = 1)# get cosine similarity score for semantic\n",
    "        jac_score = unique_name_c.apply(lambda y: jac_calc(y),axis =1) # get jaccard similarity score for vocab distance\n",
    "        lev_distance = unique_name_c.apply(lambda y: nltk.edit_distance(row['S_SEGMENT_ITEM'],y['name']), axis = 1)\n",
    "\n",
    "        xy_df = pd.DataFrame()\n",
    "        xy_df['y_name'] = unique_name_c['name']\n",
    "        xy_df['x_name'] = row['S_SEGMENT_ITEM']\n",
    "        xy_df['cos'] = cos_score\n",
    "        xy_df['jac'] = jac_score\n",
    "        xy_df['lev'] = lev_distance\n",
    "        xy_df['len(x)'] = len(row['S_SEGMENT_ITEM'])\n",
    "        xy_df['len(y)'] = unique_name_c['name'].apply(lambda y: len(y))\n",
    "\n",
    "        ml_ready_df = ml_ready_df.append(xy_df)\n",
    "    ml_ready_df = ml_ready_df.reset_index(drop = True)\n",
    "\n",
    "    inference_df = ml_ready_df.copy()\n",
    "    return inference_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_df = get_inference_data(data_unique_item,x_removed_final,y_removed_final)\n",
    "inference_df.to_csv('inference_df_filtered.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_name</th>\n",
       "      <th>x_name</th>\n",
       "      <th>cos</th>\n",
       "      <th>jac</th>\n",
       "      <th>lev</th>\n",
       "      <th>len(x)</th>\n",
       "      <th>len(y)</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>其他</td>\n",
       "      <td>其他业务</td>\n",
       "      <td>0.493589</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>内部抵消</td>\n",
       "      <td>其他业务</td>\n",
       "      <td>0.371301</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>汽车玻璃升降器</td>\n",
       "      <td>其他业务</td>\n",
       "      <td>0.258197</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>汽车发动机整机</td>\n",
       "      <td>其他业务</td>\n",
       "      <td>0.390052</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>汽车活塞</td>\n",
       "      <td>其他业务</td>\n",
       "      <td>0.182966</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85294891</th>\n",
       "      <td>原纸</td>\n",
       "      <td>移动互联网终端CPU芯片</td>\n",
       "      <td>0.394128</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85294892</th>\n",
       "      <td>复方甘草酸苷</td>\n",
       "      <td>移动互联网终端CPU芯片</td>\n",
       "      <td>0.307312</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85294893</th>\n",
       "      <td>辐照技术服务</td>\n",
       "      <td>移动互联网终端CPU芯片</td>\n",
       "      <td>0.680462</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85294894</th>\n",
       "      <td>冷却系统</td>\n",
       "      <td>移动互联网终端CPU芯片</td>\n",
       "      <td>0.420053</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85294895</th>\n",
       "      <td>粮油作物</td>\n",
       "      <td>移动互联网终端CPU芯片</td>\n",
       "      <td>0.233156</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85294896 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           y_name        x_name       cos       jac  lev  len(x)  len(y)  y\n",
       "0              其他          其他业务  0.493589  0.333333    2       4       2  1\n",
       "1            内部抵消          其他业务  0.371301  0.000000    4       4       4  0\n",
       "2         汽车玻璃升降器          其他业务  0.258197  0.000000    7       4       7  0\n",
       "3         汽车发动机整机          其他业务  0.390052  0.000000    7       4       7  0\n",
       "4            汽车活塞          其他业务  0.182966  0.000000    4       4       4  0\n",
       "...           ...           ...       ...       ...  ...     ...     ... ..\n",
       "85294891       原纸  移动互联网终端CPU芯片  0.394128  0.000000   12      12       2  0\n",
       "85294892   复方甘草酸苷  移动互联网终端CPU芯片  0.307312  0.000000   12      12       6  0\n",
       "85294893   辐照技术服务  移动互联网终端CPU芯片  0.680462  0.000000   12      12       6  0\n",
       "85294894     冷却系统  移动互联网终端CPU芯片  0.420053  0.000000   12      12       4  0\n",
       "85294895     粮油作物  移动互联网终端CPU芯片  0.233156  0.000000   12      12       4  0\n",
       "\n",
       "[85294896 rows x 8 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_df = pd.read_csv('inference_df.csv').iloc[:,1:]\n",
    "inference_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_df = inference_df.drop(columns = ['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nlp_inference(inference_df,bst):\n",
    "    '''\n",
    "    用lightGBM来预测inference_df每个产品名的类别\n",
    "    \n",
    "    Parameters:\n",
    "    inference_df (pandas dataframe): the dataframe with y_name, x_name, cos, jac, lev, len(x), len(y) columns derived from get_inference_data\n",
    "    bst (trained lightGBM.LGBMClassifier model from train_n_filter function): trained LGBMClassifier\n",
    "    \n",
    "    Returns:\n",
    "    dataframe for where each product belong and its accuracy\n",
    "    '''\n",
    "    inference_df_c = inference_df.copy()\n",
    "    temp_test = bst.predict(inference_df_c.drop(columns = ['y_name','x_name']))\n",
    "    acc = bst.predict_proba(inference_df_c.drop(columns = ['y_name','x_name']))\n",
    "    inference_df_c['perc'] = [x[1] for x in acc]\n",
    "    temp_result = inference_df_c.sort_values(by = ['x_name','perc'],ascending= False).drop_duplicates(subset = ['x_name'])\n",
    "    temp_result = temp_result[temp_result['perc']> 0.5]\n",
    "    return temp_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = nlp_inference(inference_df,bst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "result = nlp_inference(single_item_df('矿泉水',x_removed_final,y_removed_final),bst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_name</th>\n",
       "      <th>x_name</th>\n",
       "      <th>cos</th>\n",
       "      <th>jac</th>\n",
       "      <th>lev</th>\n",
       "      <th>len(x)</th>\n",
       "      <th>len(y)</th>\n",
       "      <th>perc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>饮用水</td>\n",
       "      <td>矿泉水</td>\n",
       "      <td>0.73956</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.55106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    y_name x_name      cos  jac  lev  len(x)  len(y)     perc\n",
       "152    饮用水    矿泉水  0.73956  0.0    2       3       3  0.55106"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chinese-companies-NLP\n",
    "\n",
    "There are hundred of thousands of products from each company listed on the stock market. If your job is to categorize each product into a category, how would you do it?\n",
    "\n",
    "This is what my NLP model aims to resolve. Given unmatched categories and company products, this NLP model predicts the product's category with a percentage of confidence.\n",
    "\n",
    "This model takes into account five parameters for categories and products:\n",
    "To take semantic into account:\n",
    "- cosine similarity of the semantics (Based on TencentWordEmbedding)\n",
    "To take syntactic into account:\n",
    "- jaccard similarity of the words\n",
    "- edit distance of the words\n",
    "- length of the product string\n",
    "- length of the categories string\n",
    "\n",
    "Result:\n",
    "This model is able to predict most of the products that are intuitive or vaguely representative to the categories with a high degree of accuracy (above 70% most of the time for intuitive products). Example: 矿泉水 (products) to 饮用水 (categories)\n",
    "However, the model will not be able to predict specialized products such as: A100 (products) to 打印机 (categories)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
